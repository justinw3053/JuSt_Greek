#!/usr/bin/env python3
import os
import json
import boto3
from pathlib import Path

# --- CONFIGURATION (detected from your account) ---
TABLE_NAME = "Syllabus-epb2b7bn7ncbvfrxigiwmwv2f4-NONE"
BUCKET_NAME = "amplify-webapp-justin-san-justgreekassetsbucketfc3-6cgpwitjgiqt"
REGION = "eu-central-1"
PROFILE = "greek-tutor"

BASE_DIR = Path(__file__).parent.parent
SYLLABUS_JSON = BASE_DIR / "web_app" / "data" / "syllabus.json"
AUDIO_DIR = BASE_DIR / "web_app" / "public" / "audio"

def seed_data():
    session = boto3.Session(profile_name=PROFILE, region_name=REGION)
    dynamodb = session.resource('dynamodb')
    s3 = session.client('s3')
    table = dynamodb.Table(TABLE_NAME)

    # 1. Load JSON
    with open(SYLLABUS_JSON, 'r') as f:
        syllabus = json.load(f)

    print(f"ðŸš€ Seeding {len(syllabus)} topics to DynamoDB: {TABLE_NAME}")

    # 2. Push to DynamoDB
    with table.batch_writer() as batch:
        for item in syllabus:
            # DynamoDB expects explicit types or standard JSON
            # We map our JSON fields to the Schema
            record = {
                'id': item['id'],        # Partition Key (Auto-generated by Amplify usually, but we use topicId here?)
                                         # Wait, schema said: topicId: a.id(), week: int...
                                         # Actually, Amplify Gen 2 models usually have an 'id' field as primary key.
                                         # Let's check schema: topicId is required. 'id' is implicit.
                                         # We should probably use topicId as the ID or generate a ULID.
                                         # For simplicity, let's use topicId as 'id' too.
                'topicId': item['id'],
                'week': item['week'],
                'month': item['month'],
                'title': item['title'],
                'description': item['description'],
                'content': item['content'],
                'createdAt': '2026-01-16T12:00:00Z',
                'updatedAt': '2026-01-16T12:00:00Z'
            }
            batch.put_item(Item=record)
            print(f"   [DB] Added {item['title']}")

    print("âœ… DynamoDB Seeding Complete.")

    # 3. Upload Audio to S3
    print(f"\nðŸš€ Uploading Audio to S3: {BUCKET_NAME}")
    files = list(AUDIO_DIR.glob("*.mp3"))
    for file_path in files:
        key = f"audio/{file_path.name}"
        print(f"   [S3] Uploading {key}...")
        s3.upload_file(str(file_path), BUCKET_NAME, key)

    print("âœ… Audio Upload Complete.")

if __name__ == "__main__":
    seed_data()
